# 당근 컨퍼런스 2024

## 1. Data/ML (12:00 ~ 12:30) - ㅎㅖ어져서 팝니ㄷr ☆: LLM과 임베딩 유사도로 빠르게 패턴을 바꾸는 업자 잡아내기

- [발표자료](https://file.notion.so/f/f/05b6560f-4c34-4811-bdc3-c653ef40ed27/b177dc08-2add-4a95-bb76-bb1da40ca43f/%E3%85%8E%E3%85%96%E1%84%8B%E1%85%A5%E1%84%8C%E1%85%A7%E1%84%89%E1%85%A5_%E1%84%91%E1%85%A1%E1%86%B8%E1%84%82%E1%85%B5%E3%84%B7r__LLM%E1%84%80%E1%85%AA_%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%87%E1%85%A6%E1%84%83%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%E1%84%85%E1%85%A9_%E1%84%88%E1%85%A1%E1%84%85%E1%85%B3%E1%84%80%E1%85%A6_%E1%84%91%E1%85%A2%E1%84%90%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF_%E1%84%87%E1%85%A1%E1%84%81%E1%85%AE%E1%84%82%E1%85%B3%E1%86%AB_%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%8C%E1%85%A1_%E1%84%8C%E1%85%A1%E1%86%B8%E1%84%8B%E1%85%A1%E1%84%82%E1%85%A2%E1%84%80%E1%85%B5.pdf?table=block&id=11828c3a-9f8f-808e-bc7a-f6536add7b2d&spaceId=05b6560f-4c34-4811-bdc3-c653ef40ed27&expirationTimestamp=1728357688046&signature=QywmTwFhqk7Fr4HMiuykfUyXJ8-e6EkSACb9ubM5dD0&downloadName=%E3%85%8E%E3%85%96%E1%84%8B%E1%85%A5%E1%84%8C%E1%85%A7%E1%84%89%E1%85%A5+%E1%84%91%E1%85%A1%E1%86%B8%E1%84%82%E1%85%B5%E3%84%B7r+%E2%98%86+LLM%E1%84%80%E1%85%AA+%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%87%E1%85%A6%E1%84%83%E1%85%B5%E1%86%BC+%E1%84%8B%E1%85%B2%E1%84%89%E1%85%A1%E1%84%83%E1%85%A9%E1%84%85%E1%85%A9+%E1%84%88%E1%85%A1%E1%84%85%E1%85%B3%E1%84%80%E1%85%A6+%E1%84%91%E1%85%A2%E1%84%90%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%B3%E1%86%AF+%E1%84%87%E1%85%A1%E1%84%81%E1%85%AE%E1%84%82%E1%85%B3%E1%86%AB+%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%8C%E1%85%A1+%E1%84%8C%E1%85%A1%E1%86%B8%E1%84%8B%E1%85%A1%E1%84%82%E1%85%A2%E1%84%80%E1%85%B5.pdf)

당근에서 활발하게 활동중인 전문 판매업자, 사기들을 잡아내기 위한 ML 기술 활용기

### 문제 의식

- 홈피드를 도배하는 전문 판매업자
- 전문 판매 업자?
  - 당근 중고거래는 사용하진 않지만 누군가에는 유용한 물건을 싸게 판매하는 중고 거래
  - 전문 판매 업자란
    - 사업체를 보유하고 물품을 반복 판매
    - 게시글과 채팅을 도배
    - 매너온도 등을 인위적으로 조작
  - 원래는 싼 물건을 오픈 마켓에 **비싸게 올려두고** 당근에는 그것 보다는 싸게 올려서 캡쳐하여 싸게 나눔하는 척 하는 어뷰저들
  - 전문 판매 업자에 대한 사용자 신고의 꾸준한 증가

### 기존 해결방안

- 사용자 행위 발생하기 전 -> 보안/네트워크 정책 강화
  - 앱 보안 정책 강화
  - 요청 위변조 탐지
  - 비정상 동네 인증 / 기기 제한
  - 비정상 네트워크 트래픽 차단
- 사용자 행위 발생후 -> Supervised Learning
  - 게시글에 대한 컨텐츠 패턴 탐지
- 당근 서비스 (당근의 운영 전문 자회사)를 통해 데이터 라벨링 후 학습
  - 사용자 신고 -> 당근 CS 센터 확인 후 데이터 라벨링 (Positive / Negative) -> Supervised Learning -> 운영 개발팀 로직에 반영

Supervised Learning 의 한계점
1. 라벨링 되기 전까지 학습 데이터에 반영할 수 없다
  - 게시글 작성이 되고 12시간 뒤에 공유가 되고 이 사이에 사용자 신고가 6건이 추가로 인입 되는 상황 발생
2. 다량의 데이터가 필요해 빠르게 바뀌는 패턴을 학습하기 어렵다
  - 업자를 잡는 패턴 도입후 제재가 발생하니 1분만에 제목을 바꿔서 다시 재등록하는 경우 발생
3. 전문 판매 업자 집단별 매우 다른 패턴을 가지고 있지만, "전문 판매 업자"로 합쳐서 신고를 처리하고 있다.
  - 가품/도매 땡처리 / 중고폰 등 다양한 경우를 모두 전문 판매 업자로 취급하니 성능이 계속 떨어짐

### 새로운 해결 방안

유사컨텐츠 탐지 & LLM

1. 유사 컨텐츠 로직
2. LLM Zero-Shot
3. 유사컨텐츠 로직 & LLM 로직


#### 1. 유사 컨텐츠 탐지 - 임베딩 유사도 활용

> 신고 수락 전 선제적인 모니터링 가능

컨텐츠 생성 
-> 운영 개발팀 서버에서 카프카 이벤트 컨슘 
-> 이벤트에 담긴 내용중 필요한 feature를 가공하여 임베더 서버 호출 
-> 미리 학습된 모델을 통해 컨텐츠 임베딩을 생성 
-> 생성된 임베딩을 Pinecone 에 Upsert (컨텐츠 종류에 따른 네임스페이스 구분) 
-> 설정한 기준 이상의 크기를 가진 클러스터가 발생하면 슬랙 알림 발송 
-> 어드민에서 유사 컨텐츠 검색 및 다량 신고 수락 지원

Supervised Learning 의 한계점 개선
- 새로운 패턴 선제적 탐지: 기준 이상 클러스터가 생기면 바로 알 수 있다
- 학습 데이터 불필요: 데이터가 생길 때까지 기다리지 않아도 된다.

다만...
거래완료 이미지나 기프티콘 이미지 등은 일반적인 이미지라서 지금은 유사 컨텐츠 로직을 통해 자동 신고로 확장할순 없었음

#### 2. Zero Shot with Auto Generated Prompt

> 적은 라벨링 데이터로 유연한 패턴 탐지 가능

- Zero shot Classification vs Few Shot Classification
  - Question vs Example 

1. Few Shot Classification

- 전문 판매 업자 내부에 어떤 집단이 있는지, 각 집단을 잘 표현하는 example이 무엇인지 분석 필요
- Few Shot의 근본적인 한계: 주어진 example외 추론을 잘 못함

2. Zero shot Classification

- 풀고자 하는 Task에 대한 좋은 설명을 LLM에게 제공
- Few shot의 문제를 해결하려면 전문 판매 업자 집단이 가지고 있는 특징에 대한 추상적인 설명 필요
  - LLM이 Task를 이해하도록 프롬프트 엔지니어링 하는데 많은 시간이 소요되서 자동화할수는 없을까?
  - 인간도 전문판매업자 게시글을 탐지할때 이전 맥락을 가지고 추론, 이를 LLM이 잘 모방할 수 있다는 직관을 팀 내에서 가지고 있었음

3. Zero Shot with Auto Generated Prompt

- 2스테이지 접근
  - 스테이지1: 인간이 이전에 잡힌 전문판매업자 게시글을 보고 맥락을 쌓고 특징을 이해하는 행위를 모방 LLM이 직접 특징을 추출
  - 스테이지2: LLM이 추출한 특징을 그대로 프롬프트에 사용하여 전문판매업자 게시글 탐지
- 일반 게시글 100건, 전문 판매업자 게시글 100건 -> 스테이지1 프롬프트
  - 정상과 위반을 특별하는 특징 요약
  - 품목, 패턴은 무시하고 작문 스타일에 집중
  - 높은 추상화 레벨에서 설명
    - (프롬프트 내용 첨부하기)  

> 프롬프트: 

추출된 특징 예시

스테이지 2
- 신규 게시글을 실시간으로 LLM에 제공하고 분류하도록 지시
- 지시 사항

> 프롬프트: 

완전 자동화 어드민 (화면 캡쳐 필수)


Supervised Learning 의 한계점 개선
- 추상적인 특징을 추출하고 탐지에 이용하도록 하여 ㅂㄴ화하는 패턴에 유연하게 대응 가능
- 라벨링 데이터의 양이 단 몇백건이면 충분하다


### 성과

한달간 메트릭 계산 결과

- 유사 컨텐츠 로직 Precision: 98.7%, LLM 로직 Precision: 69.4%
- LLM 로직 도입 후, 사용자가 신고한 수도 점점 감소중
- LLM 호출 비용: $545 / month (월 13만건 요청)
  - gpt-4o, gpt-4o-mini

### 결론

- 대량으로 


## 2. Data/ML (12:40 ~ 13:10) - 당근페이 데이터플랫폼 구축기

기술적 이야기 보다는 스토리 위주의 발표

### 2-1. 여러분이 회사 1호 DE가 된다면

- 어떤 일의 시작을 하는 사람은 정말 많은 권한을 가진다.
  - 변화를 이끌어나가는 기회를 얻고 싶었음

과거에 일하던 방식
- 데이터 관련 요청과 처리의 무한굴레


### 2-2. 데이터 민주화로 가는 길

데이터 민주화 != 데이터 접근
- 데이터를 볼때 편리함을 느낄 수 있도록 **툴과 문화를 개선하는 것**

데이터 민주화로 가기 위해선
- 접근성
  - 모든 구성원이 쉽게 접근할 수 있어야 함
- 이해도
  - 충분한 설명이 있어야 누구나 활용할 수 있음
- 품질 관리
  - 누구나 동일한 품질의 데이터를 사용할 수 있어야 신뢰할 수 있음
- 보안
  - 적절한 권한 관리와 보안 조치 필수
- 문화적 변화
  - 데이터 기반의 의사결정 문화 도입

회사가 크고 잘 조직화 되어있을 수록 보이지 않는 벽이 조직간에 있음

데이터 활성화 사이클
- 조직의 비효율성 식별
- 데이터를 활용하여 개선
- 인사이트를 도출하고
- 가치를 실현하고 
- 데이터 품질 강화하고 정책을 개선

=> 데이터 거버넌스
- 전사 조직 전체가 참여

데이터 거버넌스 위원회 제안
- 전사 관점의 데이터 거버넌스 수립 및 개선
- DE, DA, DBA, 보안, 서비스


### 2-3. 데이터 플랫폼 6개월 간의 과정

기존 파이프라인

여러 DB의 데이터를 DMS를 통해 S3 저장
-> 람다를 통해 데이터 전처리
-> S3로 다시 저장
-> 아테나로 분석
    - 데이터 가공이 어렵고
    - 실시간 분석이 어려움
-> Redash

람다 아키텍처 도입

람다 아키텍처 도입의 단점

- 향후 팀이 확장되는것을 고려해서 기술 복잡도가 높아지는 것을 걱정
- 기술 스택을 최대한 단순하게 구현하는 것을 목표로 함


배치 계층
- 아파치 스파크
- 대규모 데이터를 분산처리하는데 최적화
- 확장성과 성능 면에서 가장 적합한 선택
- 카펜터와 스팟 인스턴스로 운영 비용 효율화

속도 계층
- Flink 
- 시스템 성능과 가시성을 동시에 확보 가능함

서빙 계층
- DBT, Redshift, iceberg
  - DBT: 
  - Redshift: 
  - iceberg: 스냅샷 기반 버전 관리

DBT, 스파크, Flink의 공통점: SQL을 사용한다
- 셀프 서비스가 가능한 환경 구축을 목표
- yaml과 SQL 만으로 사용가능한 환경 구축



### 2-4. 데이터라는 날개를 달아

머니 결산 개선

사기 탐지

- FDS에서는 다양한 형태의 사기 탐지를 해내는 기능을 구현
- 서비스들이 강결합되어 장애에 취약한 상태였음
- CDC를 통해 다양한 시스템의 변경 사항을 수집하여 Opensearch에 데이터 적재



## Frontend (13:20 ~ 13:50) - 내 타입스크립트 코드가 이렇게 느릴 리 없어!

타입스크립트 컴파일러 혹은 타입 추론이 느려지는 경우

- 큰 규모의 코드베이스에서 개발할 때
- 작은 서비스를 오랜 기간 개발하면서 코드양이 많아지는 경우
- 타입 추론이 오래 걸리는 코드가 존재할때

### 문제 상황

배경
- 모노레포로 여러 서비스를 관리 중
- Yarn berry를 사용중
- 대부분의 서비스에서는 별 문제 없었으나 특정 서비스들에서 TS 추론 속도가 급격히 저하

TS 공식 문서에서 발견한 실마리
- 성능과 관련된 옵션 발견

`--extendedDiagnostics`
- Typescript 컴파일러가 컴파일 중 소요한 시간을 출력해주는 옵션
- 각 페이즈 별로 소요된 시간을 알 수 있다

### 성능 진단

- Preprocess
- Scan & Parse
- Bind
- Type Check
- Transform & Emit


### 분석도구

Hot Spot 분석

- 파일 하나 분석하는데 4.8초가 걸림
- 대부분 UI 컴포넌트들이 문제였음
- 스타일 

좀 더 자세히 들여다보기로 함

왜 이렇게 타입의 ID가 많이 포함되어있지?
- 사용하지 않은 `as` 타입들이 있는 것을 발견하게 됨

왜 사용하지 않은 타입들이 이렇게 많이 선언되어있지?
- keyof JSX.IntrinsicElements는 175개의 태그 이름 union type
- Row 컴포넌트를 정의하는 순간 175개 태그로 만들 수 있는 컴포넌트의 타입과 하위 타입이 정의됨


### 코드개선

2가지 방법을 고려
- Type Narrowing (타입 좁히기)
- Dynamic Type Inference


Type Narrowing
- 3가지 타입으로 좁히니 타입추론 속도 개선
- 내가 나중에 사용하는 태그가 추가 될때마다 계속 확장해야하는 번거로움이 있었음

Dynamic Type Inference
- 타입스크립트가 런타임 입력값을 바탕으로 타입을 추론하도록 함
- Generic으로 구현

결과
42초 -> 11초 (73% 단축)

### TS 성능 개선 팁 & 사례 공유

타입스크립트에서 권장하는 컴파일 되기 쉬운 코드 작성법
• Preferring Interfaces Over Intersections
• Using Type Annotations
• Preferring Base Types Over Unions
• Naming Complex Types

## Data/ML (14:00 - 14:30) - 중고거래 시멘틱서치 도입기: 꽁꽁 얼어붙은 키워드 위로 벡터가 걸어다닙니다

### 키워드 검색에서 시멘틱서치로

검색이란?
- 인덱싱: 검색 대상 문서를 DB에 색인하기
- Retrieval: 결과 후보 검색하기
- Ranking: 후보 순위 정하기

이번 발표에서는 Retrieval를 중심으로

키워드 검색이란?
- 사용자가 입력한 키워드와 DB에 저장된 텍스트 간의 일치성을 기반으로 정보를 검색
- 좋은 결과를 위해선 동의어 사전 등을 활용
- 하지만 의미적으로 유사한 물품을 효과적으로 검색하지 못함

시멘틱서치를 사용한다면?

- 기본적으로 임베딩을 사용하기 때문에 검색어와 의미적으로 유사한 물품을 검색할 수 있음
  - 한글/영어 혹은 아이폰/갤럭시 등동의어 처리 생략 가능
- 임베딩을 사용한 검색을 EBR이라 함 

### 이런 것이 좋아져요

중고거래에서'겨울'을 검색하면?
- 키워드검색: 겨울 이란 단어가 들어간 물건들만 검색
- 시멘틱서치: 겨울이란 단어가 들어가지 않아도 겨울용 의류들이 검색 결과에 포함 될 수 있음



### 모델 학습하기

데이터셋 샘플링부터 임베딩 모델 학습까지

EBR
- 임베딩 모델은 주어진 정보를 의미 공간 상의 임베딩 벡터로 변환
- 검색어와 중고거래 물품은 서로 다른 형태의 정보를 갖고 있기 때문에 각자 다른 임베딩 모델을 사용해야함
  - 이런 구조를 Two Tower 모델
- 하지만 이렇게 서로 다른 임베딩 모델에서 나온 검색어 벡터와 물품 벡터는 의미적으로 유사한 것들이라도 가까이 위치하지 않을 수 있음
  - 유저 피드백을 통해 검색어와 물품 간의 의미적인 유사성을 학습 해야함

어떤 데이터셋에 학습해야할까?
- 중고거래에서 일주일간 클릭되는 검색어-물품 쌍 약 5천만건 이상
  - 클릭 데이터를 사용하면 학습에 약 16일 소요
  - 비용적으로 거의 불가능
- 클릭 외 데이터셋은 채팅
  - 채팅까지 이어졌다면 유저의 질의가 좀 더 유의미하다고 볼 수 있음
  - 클릭 대비 4%규모
    - 유사한 학습 양상을 보임
    - Facebook Marketplace에서 발표한 논문에서도 채팅 기반 데이터셋을 사용했다고 소개
  - 노이즈가 적음
  
채팅 발생 검색어-물품 positive 샘플링
- 롱테일 검색어의 성능이 떨어짐
  - 불충분한 채팅 데이터
  - 임베딩 모델의 사전 지식에 의존 불가

다시 데이터셋 선택 고민
- "어떤 검색어" 에서 잘 못하지?
  - 좀 더 적은 데이터셋 증감으로 좀 더 잘할 수 있지 않을까?

추가학습이 필요한 검색어 파악하기
- 클릭/채팅 데이터에 학습되지 않은 원본의 임베딩 모델로 검색을 해봄
  - 임베딩 모델이 원래 잘 아는 검색어라면 일정 수준 이상의 검색 결과가 나옴
  - 임베딩 모델이 잘 모르는 검색어라면 검색어와 무관한 물품들이 무작위로 등장
- 부적절 물품을 분류하여 해당 물품에 대해서는 클릭 데이터를 통해 추가 학습
  - 부적절 물품을 분류하기 위해서 Fuzzy match 로직을 사용 
    - Fuzzy match: 완전히 일치하지 않는 문자열 비교

최종 학습 데이터셋 구성
- 전체 검색어는 채팅 데이터 사용
- 추가 학습이 필요한 검색어는 클릭 데이터 보강
- 이렇게 할 경우 전체 클릭 데이터셋 대비 8% 규모

### 4. 모델 평가하기

Retrieval 모델을 평가하려면 모든 키워드에 대해 검색된 문서들이 적합한지 라벨이 있어야함
- 클릭 데이터를 활용할 수 있지만 정확한 라벨이라고 볼 수는 없음
  - 클릭 되지 않은 문서는 틀린 데이터로 취급되는 문제가 있음
  - 검색 결과에 아예 등장하지 않았다면 클릭을 받을수 없기 때문에 모두 다 틀린 것으로 라벨링 됨

가장 간단한 건 사람이 평가
- 일관된 기준을 위해 라벨링 가이드 작성
  - 애매함을 기준으로 0~2점 할당

라벨링 가이드 라인
- 검색어 유형 분류
  - 브랜드, 특정 물품을 포함하는 상품군, 특정 물품명 (스탠바이미), 물품의 특징이나 속성(XL, 240mm)
- 질의 의도 파악
  - 검색어에서 코어 질의 의도와 마이너 질의 의도를 파악
  - Product > Brand > Item (Product + Item으로 확장) > Attribute 로 위계 설정
    - ex) 나이키 240 => 나이키 (Brand) 는 코어, 240 (Attribute)은 마이너
    - 아이폰 13 => 아이폰 (Brand): 마이너, 핸드폰 (Product): 코어
  
5200쌍의 휴먼 라벨을 확보했지만 모델을 평가하기엔 여전히 적은수
- 이 라벨과 유사한 결과를 얻을 수 있는 프롬프트 튜닝
- 효과가 있어던 것
  - 추론 과정을 출력
  - 영어로 프롬프트 작성
  - 코드 형식의 가이드
  - 다양한 예시
- 효과가 없었던 것
  - 게시글 정보 추가 (카테고리 등)
  - 프롬프트 Paraphrasing
  - 역할 제시
- 휴먼 라벨 기준 90% 이상의 성능을 보이는 LLM 프롬프트를 만들었음

대규모 라벨링 및 모델 평가

### 앞으로의 로드맵



## Frontend (15:10 - 15:40) - GraphQL Schema 기반으로 협업하고 생산성 높이기 


## Server (15:50 ~ 16:20) - 빠르게 변하는 운영 도메인에서 살아남는 코드 만들기


## Platform (16:30 - 17:00) - 비용이 왜 튀었는지 저도 몰라요

### 과거의 불편함

과거
  - 클라우드 팀이 엑셀로 비용 관리
  - 전사적으로도 비용에 대한 관심이 높지 않았음
  - 한달에 한번 추이 확인으로도 충분

점차 프로젝트가 많아지고 인원이 늘어나면서 관리가 어려워지기 시작
  - MAU가 연평균 3배 성장하는데 인프라 비용은 연평균 4배 성장

비용 가시성 확보의 필요성
- 출처를 모르는 비용을 없애자
  - Project, Team, Service 태그를 비용 태그로 활용
    - 각 리소스에 대한 Team 라벨을 추가
    - Service 라벨도 추가하여 목적을 확인할 수 있도록 함

하지만 이렇게 태그를 잘 달아도 "우리가 클라우드 잘 쓰고 있나?" 에 대한 문제를 해결할 순 없었음

넷플릭스의 Full Cycle Developers: "직접 만든 것은 직접 운영한다"
- 개발자가 직접 사용할 수 있는 빌드/프로비저닝/배포/모니터링/오퍼레이션 등 인터페이스를 제공하는 것이 SRE의 일

비용 관리를 셀프 서비스로 제공하자

기존 태그 방식의 문제 (feat. 부서개편)
- 테라폼으로 Team 태그를 관리 중이였음
  - 조직 개편시 100개가 넘는 테라폼 코드 수정이 필요했음
  - 조직 개편으로 태그 변경시 과거 비용 추적이 불가능해짐 (서로 다른 조직으로 인식)
- 위 2개 문제는 태그값이 외부에 의존하는 것이 근본적 문제
  - 서비스 오너십 필요

### Katalog 개발

서비스 오너십 문제를 해결할 수 있는 프로젝트가 필요


모니터링 서비스와 궁합이 좋았음
- Katalog에 등록된 정보로 슬랙 멘션

태그값 외부 의존성 문제
- Katalog가 서비스 관련 정보를 다 알고 있으니 리소스를 식별할 수 있는 고유값만 있으면 Katalog에서 찾을 수 있음
  - 여러 태그를 다 삭제 -> Katalog_id 값만 추가해서 관리

SRE 밋업 영상 추가

기존 태그를 제거하면 비용 조회는 어떻게? 매번 katalog_id를 찾아서 검색?

### Kost 개발

비용 시각화 인터페이스
- SRE 

Kost UI 개발

- UI를 먼저 개발하면 팀 내 공유시에도 완성된 것 처럼 받을 수 있음
- 이미 자리잡은 Kontrol 

Kost 데이터 파이프라인 개발
- AWS CUR & Usage Report

Kubecost
- 프로메테우스를 통한 메트릭 수집 -> 사용량
- AWS CUR - 단가
- 사용량 x 단가 = 파드

쿠버네티스 비용 처리
- 사용량 X 단가 = 서비스별 비용
  - 사용량
  - 단가
    - AWS츷 CPU와 메모리 간의 관계를 공재

쿠버네티스 비용 처리

Kost 개발 완료 되었지만, 미미한 사용량
- 지속적인 개선과 피드백

### 현재

- 75%의 개발조직에서 비용 리포트 구독
  - 슬랙으로 리포트 발송
- 비용에 대한 질문 방향이 개발자 -> SRE로 변화
- 개발팀에서 직접 비용 최적화
- 


### 미래

- 개발자들이 직접 비용을 업로드
- Chargeback 기반 마련
- 

