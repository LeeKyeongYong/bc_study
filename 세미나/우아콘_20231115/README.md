# 우아콘 2023.11.15

## 오프닝 ~ 키노트

### CTO 송재하님의 키노트

"모든 일의 궁극적인 목적은 고객창출과 고객만족이다"

- AI 기술을 활용한 사례
- 배달로봇 Dilly

전체적으로 세션의 큰 줄기들을 소개 해주셔서 키노트로 적합하다는 생각이 들었다.

- 서버/백엔드 세션
- 클라이언트 (웹/앱) 세션
- 개발 생산성 제고
- 디자인 시스템 
- 보안/네트워크
- PM/소프트스킬/교육

### CPO 이기호님의 키노트

크게 3가지 경험에 관심을 갖고 발전시켜나가는 배달의 민족

배달경험 / 탐색 경험 / 다양한 경험 (음식주문 그 이상의 서비스)

전단지을 대체하면서 시작한 배달의 민족

한집배달에서의 고민과 해결

ML/AI를 활용한 좀 더 정확한 배달 시간 예측


MAU 2,000만 서비스
음식 주문으로 쌓은 노하우를 가지고 다양한 서비스 출시

- 배민 스토어
  - 반찬 / 애플 제품 / 홈플러스 등 오프라인 마켓
- 대용량 특가 서비스
- 배민 우리 동네

> 장관님의 축사 영상도 있어서 놀랬다



## 대규모 트랜잭션을 처리하는 배민 주문시스템 규모에 따른 진화

- 일평균 300만 주문건
- 점심시간 / 저녁시간에 피크를 찍는 독특한 트래픽 추이

- 단일 장애 포인트 -> MSA
- 대용량 데이터 성능 문제
  - 분리된 주문 DB 안에서 Query와 Command 모두 호출되고 있어 주문 시스템 성능에 영향을 줌
  - 분리된 테이블들의 데이터를 단일 도큐먼트로 집합
- 대규모 트랜잭션
  - 쓰기요청에 대한 대응은 DB 스케일업 외애 방법이 존재하지 않아서 어려움이 발생
  - Aurora에서 직접적으로 샤딩 지원이 안되니 애플리케이션 샤딩을 구성
  - Key Based Sharding (Hash Based Sharding)
    - 구현이 간단하면 샤드 클러스터 내 샤드들에 데이터를 골고루 분배할 수 있다
    - 장비를 동적으로 추가, 제거할때 데이터 재배치가 필요하다.
  - Range Based Sharding
    - 특정 값의 범위 기반으로 샤드를 결정하기 때문에 구현이 간단
    - 데이터가 균등하게 배분되지 않아 특정 샤으데 데이터가 몰릴 수 있음
  - Directory Based Sharding
    - 중간에 Lookup Table을 두는 방식
    - 샤드 결정 로직이 Look up 테이블로 분리되어 있어 동적으로 샤드 추가하는데 유리
    - Look up 테이블이 단일 장애 포인트가 될 수 있음
- "주문 시스템은 동적 주문 데이터를 최대 30일만 저장한다" 는 특징
  - 최대 30일까지만 주문 취소가 가능
  - 단일 장애 포인트는 피하면서
  - 샤드 추가 이후 30일이 지나면 데이터는 다시 균등하게 분배 된다는 결론 내림
- 결국 Key Based Sharding (Hash Based Sharding) 선택
  - 주문 순번 % 샤드 수 = 샤드번호
- 다건 조회시 데이터 애그리게이트
  - 분산된 샤드 데이터들을 어떻게 조회 목록에 노출시킬 것인가
  - MongoDB 에 이미 조회용 데이터를 보관하고 있어서 큰 문제 없이 가능
- 복잡한 이벤트 아키텍처
  - 규칙성 없는 무분별한 이벤트 발행
  - 내/외부 이벤트 분리
    - 주줌 도메인 이벤트는 내부 이벤트로, 서비스 로직은 외부 이벤트로 정의
    - 내부 이벤트는 ZERO Payload
  - 트랜잭션 내부 외부에서 발행 실패 유무에 따라 처리가 실패하게 됨
    - 트랜잭션 아웃박스 패턴 적용
    - 실패한 메세지 발행은 아웃박스 테이블에 담긴 데이터를 스프링 배치를 통해 재발행
  - 

## [11:55 - 12:30] 추천시스템 성장 일지 - 데이터 엔지니어편

현재 상황
- 30개 이상의 추천 서비스
- 하루 5천만건의 추천 API 호출

대표적인 시스템 구성 방법 
- 학습 + 오프라인 예측
  - S3에 저장된 주문,클릭,가게 정보를 S3에 저장하고 Hive를 통해 관리
  - 학습 데이터 생성 후 GPU를 통한 모델 학습 
- 학습 + 온라인 예측
  - 실시간 모델 추론
  - 모델뿐만 아니라 모델에 전달할 피쳐 데이터 필요
  - 스파크를 통해 피쳐 데이터 생성 후 MongDB에 데이터 업로드
  - 추천 API는 MongDB에 적재된 피쳐데이터를 활용해 예측을 진행
- 요구사항과 제약 사항에 따라 결정
  - 모델의 크기, 모델 예측속도, 입력값 경우의수, 실시간 정보 필요 여부 등에 따라 선택

추천 시스템 성장 일지
- 추천 시스템을 빠르게 성장시킬 수 있었던 결정들
- (1) 추천 전달 방식의 변화
 - API 보다 더 간단하게 구현할 수 있도록 서비스 백엔드와 추천시스템팀 사이에 중앙 DB를 두고 사용
 - 서비스 백엔드에서는 중앙 DB에 데이터를 적재하고, 추천 시스템은 추천결과를 저장하고, 다시 서비스 팀은 추천팀이 저장한 데이터를 불러와서 사용
 - 초반에 이러한 방법을 사용해서 개발 요소도 적고, 관리 포인트가 적어서 **운영 부담이 적다**.
 - 다만, 다른 팀에 대한 의존성, DB에 대한 의존성 등 문제를 겪게 됨
   - 새로운 컬럼을 추가하는 등의 작업이 있을 경우 반대편에서도 항상 대응을 같이 해줘야함
   - DB에 대한 의존성도 있어 DB 업데이트가 필요하거나 DB가 지원하지 않는 기능등은 당연히 사용할 수도 없음
 - 개선) API를 통한 커뮤니케이션으로 변경
   - 단, 꼭 필요한 데이터만 주고 받는다.
   - 추천 API 내부에서 어떻게 진행되는지는 바깥 서비스에서 알 필요가 없다.
   - 얻게 된 점
     - 외부 의존성이 최소화 되어 자유로운 배포 일정이 가능
     - 실험 정보를 로깅이 가능해서 자유로운 AB 테스트가 가능
     - 최종 결과만 응답하게 되니 시스템 내부 구성을 자유롭게 가능
- (2) 컨테이너 & 쿠버네티스
  - (as-is) IDC 인프라위에서 conda 기반 GPU 학습 
    - 수행 목록
      - 학습 데이터 다운로드
      - 모델 학습
      - 모델 업로드
    - EKS 기반의 airflow 에서는 IDC 인프라로 명령
    - 어떤 문제?
      - 실행 환경 관리의 어려움
      - 독립적인 환경 구성이 없어서 학습 안정성/충돌 문제
  - (to-be) 쿠베 pod 환경 위에서 conda 수행
    - airflow에서는 쿠베 pod 명령어 수행
    - 장점
      - 의존성이 정리
      - 학습 안정성 향상
    - 단점
      - 개발 자유도 하락
        - 서버에 직접 접근해서 할 수 있는 작업들을 다 못하게 됨
      - 러닝 커브
  - 쿠버네티스의 혜택
    - 매일 같이 새로운 서비스가 출시되는 데이터 엔지니어링 생태계에서 k8s는 새로운 환경에 대한 빠르고 자유로운 실험 가능
- (3) 실시간
  - 사용자의 실시간 피드백, 실시간 추천결과, 모델의 성능을 실시간으로 확인하고 싶은 등의 요구사항 발생
  - 다 같은 실시간은 아니다
    - 모델 동작 시점) 실시간 모델 추론
    - 데이터 취득 시점) 실시간 데이터 파이프라인
  - 추천 + 실시간 = 새로운 가능성
    - 방금 본 메뉴, 방금 클릭한 가게, 방금 장바구니에 담은 상품
    - 간단한 방법
      - 서비스 백엔드에서 실시간 데이터를 함께 추천 시스템에 전달하기
      - 추천 시스템팀에서는 할 게 없음
      - 단, 또 팀들간 의존성이 또 생기게 됨
        - 모델의 요구사항이 실시간이 아니라 최근 30초 내로 변경하는 등 모델 요구사항이 변경된다면?
        - 새로운 실시간 데이터가 필요하다면?
        - 실시간 데이터 전달 과정에 문제가 발생한다면?
    - 그래서 직접 수집하자
      - 실시간 클릭 이벤트를 카프카 클러스터 등에서 수집
      - 카프카 커넥터를 통해 MongoDB에 저장
      - 저장된 데이터를 추천 시스템이 사용하여 추천시스템 API에서 추천 상품 전달

우리가 얻은 교훈

- 선택과 집중의 중요성
  - 추천 시스템을 구성하기 위해 필요한 것들이 너무 많음
  - 한정된 인원으로 성과를 내기 위해서는 선택과 집중이 필요
  - EKS를 직접관리 하는 것
    - 직접 하기엔 일정/업무 부담
    - 타 팀의 플랫폼에 의존하기엔 우리 팀 요구사항 수용 여부나 긴급 상황에 대한 대비 등이 가능할까?
    - 결국 타팀의 플랫폼에 의존하기로 함
- 목적을 잊지 말자
  - 계획에 없던 일을 하거나 
  - 목적보다 수단에 집중하거나
  - 길을 잃지 않으려고
    - 목표를 다시 한번 명확하게 설정한다.
    - 빠르게 목표를 달성한다
    - 길을 잃으면 기록하고, 돌아간다, 그리고 나중에 다시 가본다
    

## [14:00 ~ 14:45 트랙 F] 배민스토어 일반셀러 프로젝트 진행기

우리동네에서 만날 수 있는 소상공인 가게 (일반셀러) 프로젝트 시작
  
기존 프로젝트의 문제점
 
- 낮은 코드 품질
  - 코드 커버리지 10%의 적은 테스트 코드
  - 하드코딩
  - 비효율적인 로직
- 전시 서버의 커머스 플랫폼 직접 연동
  - 직접 API를 호출하는 강한 의존성
  - 급격한 트래픽 발생시 장애 전파
- 느린 API 응답 속도

### 프로젝트 실행 전략 5가지

1. 심리적 안정감
2. 목표 설정과 마음가짐
3. 팀 스터디
4. 명확한 역할 부여하기
5. 사내 플랫폼에 올라타기

#### 심리적 안정감

서로 다른 조직에 있던 백엔드 개발자들을 모아 새롭게 만든 팀  
  
그라운드룰 활용
- 팀원들이 함께 일하고 생활하면서 지켜야 할 기본 규칙
- ex) 모르는 것이 있다면 이해될 때까지 질문하자, 같은 질문을 10번을 받더라도, 착실히 답변해주자

#### 목표 설정과 마음가짐

- 목표설정
  - 일반 셀러 도입
  - 전시 아키텍처 개선
  - 전체 API 재개발
- 마음가짐
  - 우리 팀의 첫 번째 큰 도전
    - 어딘가 부딪치더라도 달려보자.
  - 즐기자
    - 최대한 경험하면서 즐기자.
  - 항상 방법은 있다.
    - 현실을 받아들이고, 그 상황에서 최선의 방법을 생각하자.

#### 팀 스터디

프로젝트 기술 검토 후 새 기술을 도입하기로 결정  
단, 팀 스터디를 진행하기로 결정

- 스터디 규칙
  - 매주 화요일 오전 1시간 진행
  - 업무와 관련된 주제
  - 치열하게 진행할 것
  - 기록을 남길 것 
    - 온보딩에 활용
- 스터디 내용
  - 타 팀의 아키텍처를 레퍼런스 삼아 스터디 하기도 함
    - 가게노출 시스템 등
  - Kotlin, Spring Webflux 등 스터디

#### 명확한 역할 부여하기

- 주 담당자/부담당자
- 가장 하고 싶은 부분을 담당하기

### 사내 플랫폼에 올라타기

플랫폼에 연동하기 보다는 필수 기능을 직접 구현하고 배포하는게 더 빨랐음
  
커뮤니케이션과 일정 조율
- 배민 스토어 이해시키기
  - 타 플랫폼 시스템 팀에 우리팀의 서비스를 이해시키기
- 우리에게 필요한 기능 자세히 공유하기
  - 우리 팀에 필요한 기능을 플랫폼 시스템 팀에 공유하기
  - 해당 플랫폼팀의 로드맵 일정에 맞춰서 제안
- 해당 플랫폼의 방향성과 로드맵

### QnA

Q. 레거시를 리팩토링 하는 시기
- 레거시를 개선하는 것은 별도의 시간이 필요하지 않음
- 매번 과제를 하면서 중간 중간 진행
- 기술적 개선이 필요한 부분은 계속 리스트업을 해두고, 과제를 진행하면서 적용

Q. 기술 도입 중 일부 팀원이 받아들이지 않거나 두려워하면
- 새로운 기술이 필요한지 아닌지 팀장이 확인 필요
- 1on1 하면서 팀원의 마음을 계속 들어봐야함
- 새로운 기술에 대한 거부감이 심하면 지켜줄 필요도 있음
- 다만, 절대 다수의 팀원들이 원하면 설득해서 진행

Q. 주니어가 사업과제를 우선하는 리더를 설득할 수 있는 방법
- 사업과제는 되게 중요함
- 이 비즈니스가 잘되지 않으면 팀 자체가 어려워질 수 있음




## [14:55 - 15:35 트랙 D] 우아한 FinOps: 클라우드 비용과 성능 사이
## [15:50 - 16:15 트랙 G] 인사할 시간도 없습니다. QA의 시간을 아껴줄 테스트 자동화 도입기
## [16:35 - 17:15 트랙 E] 어느 날 시니어가 사라졌다! 주니어 5명의 일 문화 가꾸기
## [17:30 - 18:10 트랙 G] ElastiCache 운영을 위한 우아한 가이드: 초고속 메모리 분석 툴 개발기와 레디스 운영 노하우 소개